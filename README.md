# Linux RAG â€” Assistant de commandes Linux intelligent

Un systÃ¨me RAG moderne qui transforme vos questions en langage naturel en commandes Linux prÃ©cises et sÃ©curisÃ©es. Votre copilote shell bienveillant et intelligent, entiÃ¨rement construit avec Langchain.

---

## ğŸ“‹ Description

Linux RAG est un assistant intelligent qui utilise l'IA pour vous aider Ã  trouver les bonnes commandes Linux. Posez une question en franÃ§ais, recevez la commande exacte Ã  exÃ©cuter avec une explication claire et des sources fiables.

**FonctionnalitÃ©s clÃ©s :**
- ğŸ”— **Architecture Langchain complÃ¨te** : Embeddings, Chains, Prompts
- ğŸ” **Recherche vectorielle hybride** (BM25 + embeddings OpenAI)
- âš¡ **Mode API/CLI** pour intÃ©gration et tests
- ğŸ¯ **DÃ©duplication intelligente** des rÃ©sultats
- ğŸ—ï¸ **Support multi-collections** Weaviate
- ğŸš€ **Interface Gradio moderne** avec thÃ¨me optimisÃ©

---

## ğŸ—ï¸ Architecture Langchain

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Linux RAG System                          â”‚
â”‚                    (Architecture Langchain)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Gradio    â”‚    â”‚   Langchain  â”‚    â”‚    Weaviate     â”‚  â”‚
â”‚  â”‚     UI      â”‚â—„â”€â”€â–ºâ”‚   Backend    â”‚â—„â”€â”€â–ºâ”‚   Vector DB     â”‚  â”‚
â”‚  â”‚  (Port 7860)â”‚    â”‚  (Orchestr.) â”‚    â”‚   (Port 8080)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚                   â”‚            â”‚
â”‚         â”‚                   â”‚                   â”‚            â”‚
â”‚         â–¼                   â–¼                   â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Nginx     â”‚    â”‚   OpenAI     â”‚    â”‚   HuggingFace   â”‚  â”‚
â”‚  â”‚  (Traefik)  â”‚    â”‚     API      â”‚    â”‚   Dataset       â”‚  â”‚
â”‚  â”‚  (Port 80)  â”‚    â”‚ (Embeddings) â”‚    â”‚ Linux Commands  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Flux de donnÃ©es Langchain :**
1. **Question utilisateur** â†’ Interface Gradio
2. **Embedding** â†’ `OpenAIEmbeddings` (text-embedding-3-small)
3. **Recherche hybride** â†’ Weaviate v4 (BM25 + vector)
4. **DÃ©duplication** â†’ Algorithme intelligent des doublons
5. **GÃ©nÃ©ration** â†’ `ChatOpenAI` (GPT-4o-mini) avec `PromptTemplate`
6. **Affichage** â†’ Interface utilisateur avec sources

---

## ğŸš€ Versions et Technologies

| Composant | Version | RÃ´le |
|-----------|---------|------|
| **Python** | 3.12 | Orchestration et logique mÃ©tier |
| **Langchain** | 1.0.2+ | Framework RAG principal |
| **Langchain-Core** | 0.3.0+ | Composants de base |
| **Langchain-OpenAI** | 1.0.1+ | IntÃ©gration OpenAI |
| **Langchain-Community** | 0.3.0+ | Loaders et vectorstores |
| **Weaviate** | 1.33.1 | Base de donnÃ©es vectorielle |
| **OpenAI API** | Latest | Embeddings + gÃ©nÃ©ration |
| **Gradio** | 4.44.0+ | Interface utilisateur web |
| **Docker** | Latest | Containerisation |
| **Nginx** | 1.27.0 | Reverse proxy et routing |

---

## ğŸ’¡ Concept Langchain

### Principe RAG (Retrieval-Augmented Generation)

1. **Chargement** : `datasets.load_dataset()` via HuggingFace
2. **Vectorisation** : `OpenAIEmbeddings` pour chaque commande
3. **Stockage** : Weaviate v4 avec schÃ©ma optimisÃ©
4. **Recherche** : Recherche hybride BM25 + vectorielle
5. **DÃ©duplication** : Algorithme intelligent des doublons
6. **GÃ©nÃ©ration** : `ChatOpenAI` avec `PromptTemplate` personnalisÃ©

### Architecture Langchain DÃ©taillÃ©e

```python
# Composants Langchain utilisÃ©s
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from datasets import load_dataset  # Chargement HuggingFace
```

---

## ğŸ› ï¸ Installation et lancement avec `tizy run`

> Note : `tizy run` est un raccourci de docker-compose up 

### PrÃ©requis

1. **Variables d'environnement**

Modifiez le fichier `./docker/env.sh` :

```bash
VHOST_TRAEFIK=votre-domaine.com # (exemple wikirag.fserra.databird.io)
OPENAI_API_KEY=sk-xxxx
```

2. **DÃ©pendances systÃ¨me** - Docker et Docker Compose installÃ©s et le raccourci `tizy run`

### Instructions Ã©tape par Ã©tape

#### 1. ğŸ³ DÃ©marrage des conteneurs
```bash
tizy run
```

#### 2. ğŸ”— Connexion au conteneur Python
```bash
docker exec -it wikirag-python bash
# ou
tizy connect
```

#### 3. ğŸ“ Navigation vers le dossier RAG
```bash
cd /usr/src/app/rag
```

#### 4. ğŸ—„ï¸ CrÃ©ation du schÃ©ma Weaviate (avec gestion intelligente)
```bash
python 01_create_schema.py
```
**RÃ´le :** Initialise la collection `LinuxCommand` dans Weaviate avec gestion intelligente des collections existantes.

**Options disponibles :**
- Supprimer et recrÃ©er la mÃªme collection
- CrÃ©er une nouvelle collection avec un nom diffÃ©rent
- Ignorer, ne rien faire

#### 5. ğŸ“¥ Ingestion du dataset avec Langchain
```bash
python 02_ingest.py [nom_collection]
```
**RÃ´le :** 
- Charge le dataset `hrsvrn/linux-commands-dataset` (500 premiÃ¨res entrÃ©es)
- GÃ©nÃ¨re les embeddings OpenAI via `OpenAIEmbeddings`
- InsÃ¨re les donnÃ©es vectorisÃ©es dans Weaviate v4

**Exemples :**
```bash
python 02_ingest.py                    # Utilise "LinuxCommand" par dÃ©faut
python 02_ingest.py LinuxCommandsV2   # Utilise "LinuxCommandsV2"
```

#### 6. ğŸ§ª Test en mode API/CLI avec Langchain
```bash
python 03_query.py "question" [nom_collection]
```
**RÃ´le :** Interface en ligne de commande utilisant l'architecture Langchain complÃ¨te.

**Exemples :**
```bash
python 03_query.py "trouver les fichiers volumineux"
python 03_query.py "voir les processus" LinuxCommandsV2
```

#### 7. ğŸŒ Lancement de l'interface Gradio avec Langchain
```bash
python 04_gradio.py
```
**RÃ´le :** DÃ©marre l'interface web complÃ¨te avec :
- Architecture Langchain intÃ©grÃ©e
- Recherche hybride avec dÃ©duplication
- Interface moderne avec thÃ¨me Soft
- Affichage des sources utilisÃ©es
- Gestion d'erreurs robuste

âœ… L'interface est accessible via https://votre-domaine.com/rag

#### 8. ğŸ“š Aide et documentation
```bash
python 00_help.py
```
**RÃ´le :** Affiche la documentation complÃ¨te et les exemples d'utilisation.

---

## ğŸ“Š Dataset Linux Commands

### Source
- **Dataset** : `hrsvrn/linux-commands-dataset` (HuggingFace)
- **Taille** : 500 commandes sÃ©lectionnÃ©es (optimisÃ© pour les tests)
- **Format** : Paires question/rÃ©ponse en anglais
- **Couverture** : Filesystem, rÃ©seau, processus, administration...

### Structure des donnÃ©es
```json
{
  "input": "Description de la tÃ¢che en anglais",
  "output": "Commande Linux correspondante"
}
```

### Exemples d'entrÃ©es
- **Input** : "Recursively change ownership of a directory to user 'john'"
- **Output** : "chown -R john:john /path/to/directory"

- **Input** : "Find all files modified in the last 7 days"
- **Output** : "find . -type f -mtime -7"

### Vectorisation Langchain
- **ModÃ¨le** : `text-embedding-3-small` (OpenAI)
- **Dimension** : 1536
- **MÃ©thode** : ConcatÃ©nation description + commande
- **Index** : HNSW (Hierarchical Navigable Small World)
- **Framework** : `OpenAIEmbeddings` de Langchain

---

## ğŸ”§ Configuration avancÃ©e

### ParamÃ¨tres Weaviate v4
```python
# Recherche hybride
alpha=0.5          # Ã‰quilibre BM25/vectoriel
limit=12           # Nombre de candidats (pour dÃ©duplication)
return_metadata=["score"]  # Scores de pertinence

# Index vectoriel
Configure.VectorIndex.hnsw()  # Algorithme HNSW
```

### ParamÃ¨tres Langchain OpenAI
```python
# Embeddings
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# GÃ©nÃ©ration
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.0,  # DÃ©terministe
    openai_api_key=os.getenv("OPENAI_API_KEY")
)
```

### DÃ©duplication intelligente
```python
# Algorithme de dÃ©duplication
seen_commands = set()
unique_results = []

for obj in results:
    cmd = obj.properties.get("command", "")
    if cmd and cmd not in seen_commands:
        seen_commands.add(cmd)
        unique_results.append(obj)
        if len(unique_results) >= 4:
            break
```

---

## ğŸ“ Structure du projet

```
root/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml      # Configuration des conteneurs
â”‚   â”œâ”€â”€ nginx/
â”‚   â”‚   â”œâ”€â”€ nginx.conf          # Configuration Nginx
â”‚   â”‚   â””â”€â”€ vhost.conf          # Virtual host
â”‚   â””â”€â”€ start.sh                # Script de dÃ©marrage
â”œâ”€â”€ web/app/rag/
â”‚   â”œâ”€â”€ 00_help.py             # Script d'aide et documentation
â”‚   â”œâ”€â”€ 01_create_schema.py     # CrÃ©ation schÃ©ma Weaviate (gestion intelligente)
â”‚   â”œâ”€â”€ 02_ingest.py           # Ingestion dataset avec Langchain
â”‚   â”œâ”€â”€ 03_query.py            # Interface CLI/API avec Langchain
â”‚   â”œâ”€â”€ 04_gradio.py           # Interface web Gradio avec Langchain
â”‚   â””â”€â”€ requirements.txt        # DÃ©pendances Python (Langchain inclus)
â””â”€â”€ README.md                   # Documentation complÃ¨te
```

---

## ğŸ§ª Exemples d'utilisation

### Question simple
**Input :** "Comment voir l'espace disque utilisÃ© ?"
**Output :**
```bash
df -h
```
Affiche l'utilisation des disques en format lisible.

### Question complexe
**Input :** "Trouver tous les fichiers .log plus gros que 100MB modifiÃ©s cette semaine"
**Output :**
```bash
find /var/log -name "*.log" -size +100M -mtime -7
```
Recherche les fichiers de log volumineux modifiÃ©s rÃ©cemment.

### Interface Gradio
- **Question** : "Compresser un dossier en tar.gz"
- **RÃ©ponse** : Commande `tar -czf archive.tar.gz dossier/`
- **Sources** : Affichage des 4 sources les plus pertinentes

---

## ğŸ” RequÃªtes GraphQL Weaviate

### AccÃ¨s Ã  l'interface GraphQL
```
https://votre-domaine.com/v1/graphql
```

### RequÃªtes utiles

#### ğŸ“‹ Lister toutes les commandes (limitÃ©)
```graphql
{
  Get {
    LinuxCommand(limit: 10) {
      description
      command
    }
  }
}
```

#### ğŸ” Recherche textuelle
```graphql
{
  Get {
    LinuxCommand(
      bm25: {
        query: "find files"
      }
      limit: 5
    ) {
      description
      command
      _additional {
        score
      }
    }
  }
}
```

#### ğŸ“Š Statistiques de la collection
```graphql
{
  Aggregate {
    LinuxCommand {
      meta {
        count
      }
    }
  }
}
```

---

## ğŸ¯ FonctionnalitÃ©s avancÃ©es

### Gestion multi-collections
- **Collections multiples** : Support de plusieurs collections simultanÃ©es
- **Nommage flexible** : CrÃ©ation de collections avec noms personnalisÃ©s
- **Isolation des donnÃ©es** : Chaque collection est indÃ©pendante

### DÃ©duplication intelligente
- **Ã‰limination des doublons** : Algorithme basÃ© sur les commandes uniques
- **DiversitÃ© des rÃ©sultats** : Recherche Ã©largie pour plus de variÃ©tÃ©
- **Ordre prÃ©servÃ©** : Les rÃ©sultats les plus pertinents sont prioritaires

### Interface utilisateur moderne
- **ThÃ¨me Soft** : Design Ã©purÃ© et professionnel
- **Responsive** : Adaptation mobile et desktop
- **Sources visibles** : Affichage des sources utilisÃ©es
- **Gestion d'erreurs** : Messages d'erreur clairs et informatifs

---

## ğŸ‘¤ Auteur

**Fabien SERRA-MONTINERI**  
*Majeur de promotion - Formation Data Science*

---

## ğŸ“ Notes techniques

### AmÃ©liorations apportÃ©es
- **Architecture hybride** : Weaviate v4 + Langchain pour compatibilitÃ© maximale
- **Gestion des warnings** : Suppression des warnings non critiques
- **Robustesse** : Gestion d'erreurs et validation des entrÃ©es
- **Performance** : DÃ©duplication et optimisation des requÃªtes

### Technologies modernes
- **Langchain 1.0+** : Framework RAG de rÃ©fÃ©rence
- **Weaviate v4** : Base vectorielle nouvelle gÃ©nÃ©ration
- **GPT-4o-mini** : ModÃ¨le OpenAI optimisÃ©
- **Docker** : Containerisation complÃ¨te